values = matrix(nrow=dim(traits)[1], ncol=1)#
values[,1] = traits[tree2$tip.label,"croplands"]#
colourScale = colorRampPalette(brewer.pal(9,"YlGn"))(101)#
# colourScale = colorRampPalette(c("white","lemonchiffon2"),bias=1)(101)#
cols = colourScale[(((values-min(values))/(max(values)-min(values)))*100)+1]#
tree3 = tree2; tree3$tip.label = gsub("B_", "    B. ", tree3$tip.label)#
dev.new(width=7, height=7.5); par(oma=c(0,0,0,0), mar=c(0.8,1.2,0.5,2.2), lwd=0.2)#
plot(tree3, show.tip.label=T, edge.width=0.5, cex=0.6, align.tip.label=3, col="gray30")#
for (i in 1:dim(tree3$edge)[1])#
	{#
		if (!tree3$edge[i,2]%in%tree3$edge[,1])#
			{#
				nodelabels(node=tree3$edge[i,2], pch=16, cex=1.2, col=cols[tree3$edge[i,2]])#
				nodelabels(node=tree3$edge[i,2], pch=1, cex=1.2, col="gray30", lwd=0.5)#
			}#
	}#
mat = matrix(nrow=1, ncol=2); mat[1,1] = min(values); mat[1,2] = max(values); rast = raster(matrix(mat))#
plot(rast, legend.only=T, add=T, col=colorRampPalette(brewer.pal(9,"YlGn"))(101), legend.width=0.5, alpha=1,#
	 legend.shrink=0.3, smallplot=c(0.11,0.123,0.15,0.50), legend.args=list(text="", cex=0.8, line=0.5, col="gray30"),#
	 axis.args=list(cex.axis=0.7, lwd=0, lwd.tick=0.2, tck=-0.5, line=0, mgp=c(0,0.4,0), at=seq(0,35,5),#
	 labels=c("0.00","0.05","0.10","0.15","0.20","0.25","0.30","0.35")))#
add.scale.bar(length=NULL, ask=F, lwd=0.5 , lcol ="gray30", cex=0.7)#
title1 = "Importance of"; mtext(title1, side=3, line=-16.2, at=0.09, cex=0.75, font=1, col="gray30")#
title2 = "grasslands as"; mtext(title2, side=3, line=-17.0, at=0.09, cex=0.75, font=1, col="gray30")#
title3 = "a SDM predictor"; mtext(title3, side=3, line=-17.8, at=0.09, cex=0.75, font=1, col="gray30")
values = matrix(nrow=dim(traits)[1], ncol=1)#
values[,1] = traits[tree2$tip.label,"croplands"]#
colourScale = colorRampPalette(brewer.pal(9,"YlGn"))(101)#
# colourScale = colorRampPalette(c("white","lemonchiffon2"),bias=1)(101)#
cols = colourScale[(((values-min(values))/(max(values)-min(values)))*100)+1]#
tree3 = tree2; tree3$tip.label = gsub("B_", "    B. ", tree3$tip.label)#
dev.new(width=7, height=7.5); par(oma=c(0,0,0,0), mar=c(0.8,1.2,0.5,2.2), lwd=0.2)#
plot(tree3, show.tip.label=T, edge.width=0.5, cex=0.6, align.tip.label=3, col="gray30")#
for (i in 1:dim(tree3$edge)[1])#
	{#
		if (!tree3$edge[i,2]%in%tree3$edge[,1])#
			{#
				nodelabels(node=tree3$edge[i,2], pch=16, cex=1.2, col=cols[tree3$edge[i,2]])#
				nodelabels(node=tree3$edge[i,2], pch=1, cex=1.2, col="gray30", lwd=0.5)#
			}#
	}#
mat = matrix(nrow=1, ncol=2); mat[1,1] = min(values); mat[1,2] = max(values); rast = raster(matrix(mat))#
plot(rast, legend.only=T, add=T, col=colorRampPalette(brewer.pal(9,"YlGn"))(101), legend.width=0.5, alpha=1,#
	 legend.shrink=0.3, smallplot=c(0.11,0.123,0.15,0.50), legend.args=list(text="", cex=0.8, line=0.5, col="gray30"),#
	 axis.args=list(cex.axis=0.7, lwd=0, lwd.tick=0.2, tck=-0.5, line=0, mgp=c(0,0.4,0), at=seq(0,35,5),#
	 labels=c("0.00","0.05","0.10","0.15","0.20","0.25","0.30","0.35")))#
add.scale.bar(length=NULL, ask=F, lwd=0.5 , lcol ="gray30", cex=0.7)#
title1 = "Importance of"; mtext(title1, side=3, line=-16.1, at=0.10, cex=0.75, font=1, col="gray30")#
title2 = "grasslands as"; mtext(title2, side=3, line=-16.9, at=0.10, cex=0.75, font=1, col="gray30")#
title3 = "a SDM predictor"; mtext(title3, side=3, line=-17.7, at=0.10, cex=0.75, font=1, col="gray30")
l = length(tree3$tip.label)+1
l
l1 = length(tree3$tip.label)+1
l1
l1 = length(tree3$tip.label)+1; l2 = (2*l1)-1#
internalNodes = seq(l1, l2, 1)
internalNodes
length(tree3$tip.label)
(2*l1)-1
dev.new(width=7, height=7.5); par(oma=c(0,0,0,0), mar=c(0.8,1.2,0.5,2.2), lwd=0.2)#
plot(tree3, show.tip.label=T, show.node.label=T, edge.width=0.5, cex=0.6, align.tip.label=3, col="gray30")#
for (i in 1:dim(tree3$edge)[1])#
	{#
		if (!tree3$edge[i,2]%in%tree3$edge[,1])#
			{#
				nodelabels(node=tree3$edge[i,2], pch=16, cex=1.2, col=cols[tree3$edge[i,2]])#
				nodelabels(node=tree3$edge[i,2], pch=1, cex=1.2, col="gray30", lwd=0.5)#
			}#
	}#
mat = matrix(nrow=1, ncol=2); mat[1,1] = min(values); mat[1,2] = max(values); rast = raster(matrix(mat))#
plot(rast, legend.only=T, add=T, col=colorRampPalette(brewer.pal(9,"YlGn"))(101), legend.width=0.5, alpha=1,#
	 legend.shrink=0.3, smallplot=c(0.11,0.123,0.15,0.50), legend.args=list(text="", cex=0.8, line=0.5, col="gray30"),#
	 axis.args=list(cex.axis=0.7, lwd=0, lwd.tick=0.2, tck=-0.5, line=0, mgp=c(0,0.4,0), at=seq(0,35,5),#
	 labels=c("0.00","0.05","0.10","0.15","0.20","0.25","0.30","0.35")))#
add.scale.bar(length=NULL, ask=F, lwd=0.5 , lcol ="gray30", cex=0.7)#
title1 = "Importance of"; mtext(title1, side=3, line=-16.1, at=0.10, cex=0.75, font=1, col="gray30")#
title2 = "grasslands as"; mtext(title2, side=3, line=-16.9, at=0.10, cex=0.75, font=1, col="gray30")#
title3 = "a SDM predictor"; mtext(title3, side=3, line=-17.7, at=0.10, cex=0.75, font=1, col="gray30")
node.labels(tree3)
str(tree3)
plot(tree3, show.tip.label=T, show.node.label=T, edge.width=0.5, cex=0.6, align.tip.label=3, col="gray30")#
l1 = length(tree3$tip.label)+1; l2 = (2*length(tree3$tip.label))-1#
nodelabels(tree3$node.label, node=l1:l2, adj = c(-0.2, -0.2), cex=0.3)
nodelabels(tree3$node.label, node=l1:l2, adj = c(-0.5), cex=0.3)
values = matrix(nrow=dim(traits)[1], ncol=1)#
values[,1] = traits[tree2$tip.label,"croplands"]#
colourScale = colorRampPalette(brewer.pal(9,"YlGn"))(101)#
# colourScale = colorRampPalette(c("white","lemonchiffon2"),bias=1)(101)#
cols = colourScale[(((values-min(values))/(max(values)-min(values)))*100)+1]#
tree3 = tree2; tree3$tip.label = gsub("B_", "    B. ", tree3$tip.label)#
dev.new(width=7, height=7.5); par(oma=c(0,0,0,0), mar=c(0.8,1.2,0.5,2.2), lwd=0.2)#
plot(tree3, show.tip.label=T, show.node.label=T, edge.width=0.5, cex=0.6, align.tip.label=3, col="gray30")#
l1 = length(tree3$tip.label)+1; l2 = (2*length(tree3$tip.label))-1#
nodelabels(tree3$node.label, node=l1:l2, adj = c(-0.5), cex=0.3)
plot(tree3, show.tip.label=T, show.node.label=T, edge.width=0.5, cex=0.6, align.tip.label=3, col="gray30")#
l1 = length(tree3$tip.label)+1; l2 = (2*length(tree3$tip.label))-1#
nodelabels(tree3$node.label, node=l1:l2, cex=0.3)
tree3$node.label
l1:l2
length(tree3$tip.label)+1
l1 = length(tree3$tip.label)+1; l2 = (2*length(tree3$tip.label))-2
plot(tree3, show.tip.label=T, show.node.label=T, edge.width=0.5, cex=0.6, align.tip.label=3, col="gray30")#
l1 = length(tree3$tip.label)+1; l2 = (2*length(tree3$tip.label))-2#
nodelabels(tree3$node.label, node=l1:l2, cex=0.3)
values = matrix(nrow=dim(traits)[1], ncol=1)#
values[,1] = traits[tree2$tip.label,"croplands"]#
colourScale = colorRampPalette(brewer.pal(9,"YlGn"))(101)#
# colourScale = colorRampPalette(c("white","lemonchiffon2"),bias=1)(101)#
cols = colourScale[(((values-min(values))/(max(values)-min(values)))*100)+1]#
tree3 = tree2; tree3$tip.label = gsub("B_", "    B. ", tree3$tip.label)#
dev.new(width=7, height=7.5); par(oma=c(0,0,0,0), mar=c(0.8,1.2,0.5,2.2), lwd=0.2)#
plot(tree3, show.tip.label=T, show.node.label=T, edge.width=0.5, cex=0.6, align.tip.label=3, col="gray30")#
l1 = length(tree3$tip.label)+1; l2 = (2*length(tree3$tip.label))-2#
for (i in 1:dim(tree3$edge)[1])#
	{#
		if (!tree3$edge[i,2]%in%tree3$edge[,1])#
			{#
				nodelabels(node=tree3$edge[i,2], pch=16, cex=1.2, col=cols[tree3$edge[i,2]])#
				nodelabels(node=tree3$edge[i,2], pch=1, cex=1.2, col="gray30", lwd=0.5)#
			}#
	}#
mat = matrix(nrow=1, ncol=2); mat[1,1] = min(values); mat[1,2] = max(values); rast = raster(matrix(mat))#
plot(rast, legend.only=T, add=T, col=colorRampPalette(brewer.pal(9,"YlGn"))(101), legend.width=0.5, alpha=1,#
	 legend.shrink=0.3, smallplot=c(0.11,0.123,0.15,0.50), legend.args=list(text="", cex=0.8, line=0.5, col="gray30"),#
	 axis.args=list(cex.axis=0.7, lwd=0, lwd.tick=0.2, tck=-0.5, line=0, mgp=c(0,0.4,0), at=seq(0,35,5),#
	 labels=c("0.00","0.05","0.10","0.15","0.20","0.25","0.30","0.35")))#
add.scale.bar(length=NULL, ask=F, lwd=0.5 , lcol ="gray30", cex=0.7)#
title1 = "Importance of"; mtext(title1, side=3, line=-16.1, at=0.10, cex=0.75, font=1, col="gray30")#
title2 = "grasslands as"; mtext(title2, side=3, line=-16.9, at=0.10, cex=0.75, font=1, col="gray30")#
title3 = "a SDM predictor"; mtext(title3, side=3, line=-17.7, at=0.10, cex=0.75, font=1, col="gray30")
print(K_pValues)
library(raster); library(fields); library(RColorBrewer); library(dismo); library(rJava); library(gbm); library(pgirmess)#
options(java.parameters="-Xmx15000m"); source("decreaseResolution.r"); source("landCoverRasters.r")#
#
datasetsDirectory = "Bombus_observations_2"#
resolution = "16"; # resolution = "04"#
e_1 = extent(-19, 88, 19, 82); e_2 = extent(-15, 84, 23, 78)#
subsampling_adjacent_cells = TRUE; background_cell = TRUE#
background_mask = FALSE; human_pop_density_bias = FALSE#
cols = rev(colorRampPalette(brewer.pal(11,"RdYlBu"))(121)[11:101])#
plotWidth = 7.0; plotHeight = 6.2#
datasets = list.files(datasetsDirectory); # datasets = datasets[40]#
datasets = gsub(".csv","",datasets[which(grepl(".csv",datasets))])
importances = read.csv("MaxEnt_importances.csv", header=T)
head(importances)
row.names(importances)
importances = importances[-which(row.names(importances)),]
write.csv(importances, "MaxEnt_importances.csv", quote=F)
importances = read.csv("MaxEnt_importances.csv", header=T)
importances = importances[-which(row.names(importances)),]
row.names(importances)
importances = importances[-which(row.names(importances)=="B_wurflenii"),]
importances
pca = dudi.pca(importances, scannf=F, nf=19); lis = pca$li[,1:2]; cos = pca$co
??dudi.pca
library(ade4)
importances = read.csv("MaxEnt_importances.csv", header=T)#
importances = importances[-which(row.names(importances)=="B_wurflenii"),]#
pca = dudi.pca(importances, scannf=F, nf=19); lis = pca$li[,1:2]; cos = pca$co
dev.new(width=7, height=6); par(mar=c(3,3,1.5,1.5))#
plot(lis, col="gray30", cex=0.7, pch=16, ann=F, axes=F, xlim=c(-6.3,4.3))#
# s.corcircle(2*cos,xax=1,yax=2,box=F,sub="",csub=1,clabel=1.5,possub="topleft",grid=T,cgrid=1,full=T,add.plot=T)#
text(lis[,1], lis[,2], labels=gsub("B_","",row.names(lis)), cex=0.6, col="gray30", pos=4, offset=0.25)#
axis(side=1, lwd.tick=0.2, cex.axis=0.6, lwd=0.2, tck=-0.010, col.axis="gray30", mgp=c(0,0,0), at=seq(-8,5,1))#
axis(side=2, lwd.tick=0.2, cex.axis=0.6, lwd=0.2, tck=-0.010, col.axis="gray30", mgp=c(0,0.3,0), at=seq(-9,5,1))#
title(xlab="PCA axis 1", cex.lab=0.7, mgp=c(1.0,0,0), col.lab="gray30")#
title(ylab="PCA axis 2", cex.lab=0.7, mgp=c(1.3,0,0), col.lab="gray30")
importances
importances[c("brodmannicus","campestris"),]
importances[c("B_brodmannicus","B_campestris"),]
datasets
h=8
if (background_cell == TRUE)#
					{#
						null_raster[!(1:length(null_raster[]))%in%background_cells] = NA#
						human_pop_density_log[!(1:length(human_pop_density_log[]))%in%background_cells] = NA#
					}#
				if ((background_mask == TRUE)&(human_pop_density_bias == TRUE))#
					{#
						background_r = mask(human_pop_density_log, background_masks[[h]]); stack = mask(rasters_stacks, background_masks[[h]])#
					}#
				if ((background_mask == TRUE)&(human_pop_density_bias == FALSE))#
					{#
						background_r = mask(null_raster, background_masks[[h]]); stack = mask(rasters_stacks, background_masks[[h]])#
					}#
				if ((background_mask == FALSE)&(human_pop_density_bias == FALSE))#
					{#
						background_r = null_raster; stack = rasters_stacks#
					}#
				observations = observations_list[[h]]#
				pseudo_absences = xyFromCell(background_r, sample(which(!is.na(values(background_r))),10000,prob=values(background_r)[!is.na(values(background_r))]))#
				presences = cbind(observations, rep(1,dim(observations)[1]))#
				absences = cbind(pseudo_absences, rep(0,dim(pseudo_absences)[1]))#
				colnames(absences)[1] = "longitude"; colnames(absences)[2] = "latitude"#
				colnames(absences)[3] = "response"; colnames(presences)[3] = "response"
library(raster); library(fields); library(RColorBrewer); library(dismo); library(rJava); library(gbm); library(pgirmess)#
options(java.parameters="-Xmx15000m"); source("decreaseResolution.r"); source("landCoverRasters.r")#
#
datasetsDirectory = "Bombus_observations_2"#
resolution = "16"; # resolution = "04"#
e_1 = extent(-19, 88, 19, 82); e_2 = extent(-15, 84, 23, 78)#
subsampling_adjacent_cells = TRUE; background_cell = TRUE#
background_mask = FALSE; human_pop_density_bias = FALSE#
cols = rev(colorRampPalette(brewer.pal(11,"RdYlBu"))(121)[11:101])#
plotWidth = 7.0; plotHeight = 6.2#
datasets = list.files(datasetsDirectory); # datasets = datasets[40]#
datasets = gsub(".csv","",datasets[which(grepl(".csv",datasets))])#
#
# 1. Preparing the environmental rasters#
#
	# 1.1. Cropping the WorldClim 2.0 raster files (source: http://worldclim.org/bioclim)#
#
bioclimatic_variables = as.character(read.csv("Bioclimatic_variables.csv",header=T)[,"short_name"])#
files = list.files("WorldClim_2.0_rasters"); rasters_1 = list(); c = 0#
for (i in 1:length(files))#
	{#
		if ((grepl(".tif",files[i]) == TRUE)&(!file.exists(paste0("WorldClim_2.0_rasters/",gsub(".tif",paste0("_",resolution,".asc"),gsub("_2.5m","",files[i]))))))#
			{#
				rast = crop(raster(paste0("WorldClim_2.0_rasters/",files[i])),e_1)#
				if (resolution == "16") rast = decreaseResolution(rast, 4)#
				writeRaster(rast, paste0("WorldClim_2.0_rasters/",gsub(".tif",paste0("_",resolution,".asc"),gsub("_2.5m","",files[i]))))#
				c = c+1; rast = raster(paste0("WorldClim_2.0_rasters/",files[i])); id = unlist(strsplit(files[i],"_"))[length(unlist(strsplit(files[i],"_")))]#
				names(rast) = bioclimatic_variables[as.numeric(gsub(".tif","",id))]; rasters_1[[c]] = rast#
			}	else		{#
				if (grepl(paste0("_",resolution,".asc"),files[i]) == TRUE)#
					{#
						c = c+1; rast = raster(paste0("WorldClim_2.0_rasters/",files[i])); id = unlist(strsplit(files[i],"_"))[length(unlist(strsplit(files[i],"_")))-1]#
						names(rast) = bioclimatic_variables[as.numeric(gsub(".asc","",id))]; crs(rast) = CRS("+proj=longlat +datum=WGS84"); rasters_1[[c]] = rast#
					}#
			}#
	}#
#
	# 1.2. Preparing the land cover variables (source: https://lpdaac.usgs.gov/dataset_discovery/modis/modis_products_table/mcd12q1)#
#
rasters_2 = list(); land_cover_variables = c("barren_vegetation","closed_shrubland","croplands","deciduous_broadleaf_forest",#
								"deciduous_needleleaf_forest", "evergreen_broadleaf_forest","evergreen_needleleaf_forest","grasslands",#
								"mixed_forests","open_shrublands","savannas","snow_ice","urban_areas","wetlands","woody_savannas")#
if (!file.exists(paste0("Land_cover_rasters/CL_",land_cover_variables[1],"_",resolution,".asc")))#
	{#
		cover_land = crop(raster("IGBP_land_cover.tif"), e_1)#
		if (resolution == "04") landCoverRasters(rast=cover_land, R=5)#
		if (resolution == "16") landCoverRasters(rast=cover_land, R=20)#
	}#
for (i in 1:length(land_cover_variables))#
	{#
		rast = raster(paste0("Land_cover_rasters/CL_",land_cover_variables[i],"_",resolution,".asc"))#
		names(rast) = land_cover_variables[i]; rasters_2[[i]] = rast#
		# print(c(i, length(unique(extract(rast,observations)))))#
	}#
#
	# 1.3. Preparing the Natural Earth background raster (visualisation only)#
#
background = crop(raster("Background_raster.tif"), e_1); background[background[]==106] = NA; r = background#
cols_background = colorRampPalette(c("grey","white"),bias=1)(max(r[],na.rm=T)-min(r[],na.rm=T))[1:(max(r[],na.rm=T)-min(r[],na.rm=T))]#
#
# 2. Variables selection based on pairwise correlations#
#
observations_list = list(); N_tot_1 = 0; N_tot_2 = 0#
for (h in 1:length(datasets))#
	{#
		observations = read.csv(paste0(datasetsDirectory,"/",datasets[h],".csv"), header=T)#
		N_tot_1 = N_tot_1 + dim(observations)[1]#
		observations = unique(observations[,c("longitude","latitude")])#
		N_tot_2 = N_tot_2 + dim(observations)[1]#
		observations = observations[!is.na(extract(rasters_1[[1]], observations)),]#
		observations = observations[!is.na(extract(rasters_2[[1]], observations)),]#
		observations_list[[h]] = observations; cat(datasets[h]); cat("\n")#
		if (h == 1)#
			{#
				xmin = min(observations[,1]); xmax = max(observations[,1])#
				ymin = min(observations[,2]); ymax = max(observations[,2])#
			}	else		{#
				if (xmin > min(observations[,1])) xmin = min(observations[,1])#
				if (xmax < max(observations[,1])) xmax = max(observations[,1])#
				if (ymin > min(observations[,2])) ymin = min(observations[,2])#
				if (ymax < max(observations[,2])) ymax = max(observations[,2])#
			}#
	}#
#
for (h in 1:length(datasets)) # to print the pairs of predictors with a Pearson's r >= 0.7, and the non-variable predictors#
	{#
		observations = observations_list[[h]]#
		for (i in 1:length(rasters_1))#
			{#
				rast = crop(rasters_1[[i]], e_2); res(rast) = res(rasters_1[[1]])#
				crs(rast) = CRS("+proj=longlat +datum=WGS84"); names(rast) = names(rasters_1[[i]]); rasters_1[[i]] = rast#
			}#
		extractions = matrix(nrow=dim(observations)[1], ncol=length(rasters_1)); colnames(extractions) = bioclimatic_variables#
		correlations = matrix(nrow=length(rasters_1), ncol=length(rasters_1)); row.names(correlations) = bioclimatic_variables #
		for (i in 1:length(rasters_1)) extractions[,names(rasters_1[[i]])] = extract(rasters_1[[i]], observations)#
		for (i in 1:length(rasters_1))#
			{#
				for (j in 1:i)#
					{#
						correlations[i,j] = cor(extractions[,i],extractions[,j]); correlations[j,i] = correlations[i,j]#
					}#
			}#
		for (i in 2:length(rasters_1))#
			{#
				for (j in 1:(i-1))#
					{#
						if ((!is.na(correlations[i,j]))&(abs(correlations[i,j]) >= 0.7))#
							{#
								# cat(paste0("	    r >= 0.7 - BIO ",bioclimatic_variables[i]," - BIO ",bioclimatic_variables[j])); cat("\n")#
								cat(paste0("	    r >= 0.7 - BIO ",i," - BIO ",j)); cat("\n")#
							}#
					}#
			}#
		for (i in 1:length(rasters_2))#
			{#
				rast = crop(rasters_2[[i]], e_2); res(rast) = res(rasters_1[[1]]); extent(rast) = extent(rasters_1[[1]])#
				crs(rast) = CRS("+proj=longlat +datum=WGS84"); names(rast) = names(rasters_2[[i]]); rasters_2[[i]] = rast#
			}#
		extractions = matrix(nrow=dim(observations)[1], ncol=length(rasters_2)); colnames(extractions) = land_cover_variables#
		correlations = matrix(nrow=length(rasters_2), ncol=length(rasters_2)); row.names(correlations) = land_cover_variables #
		for (i in 1:length(rasters_2)) extractions[,names(rasters_2[[i]])] = extract(rasters_2[[i]], observations)#
		for (i in 1:length(rasters_2))#
			{#
				for (j in 1:i)#
					{#
						correlations[i,j] = cor(extractions[,i],extractions[,j]); correlations[j,i] = correlations[i,j]#
					}#
			}#
		for (i in 2:length(rasters_2))#
			{#
				for (j in 1:(i-1))#
					{#
						if ((!is.na(correlations[i,j]))&(abs(correlations[i,j]) >= 0.7))#
							{#
								cat(paste0("    r >= 0.7 - ",land_cover_variables[i]," - ",land_cover_variables[j])); cat("\n")#
							}#
					}#
			}#
		for (i in 1:length(rasters_2))#
			{#
				if (length(unique(extractions[,i])) == 1)#
					{#
						cat(paste0("    no variation in ",land_cover_variables[i],", variable number ",i)); cat("\n")#
					}#
			}#
	}#
rasters1_to_select = c(1,4,12,15); rasters2_to_select = 1:length(rasters_2); rasters_stacks = list()#
for (h in 1:length(datasets))#
	{#
		if (h == 1)#
			{#
				rasters = list()#
				for (i in rasters1_to_select)#
					{#
						rast = crop(rasters_1[[i]], e_2); res(rast) = res(rasters_1[[1]])#
						crs(rast) = CRS("+proj=longlat +datum=WGS84"); names(rast) = names(rasters_1[[i]])#
						rasters[[length(rasters)+1]] = rast#
					}#
				for (i in rasters2_to_select)#
					{#
						rast = crop(rasters_2[[i]], e_2); res(rast) = res(rasters_1[[1]]); extent(rast) = extent(rasters_1[[1]])#
						crs(rast) = CRS("+proj=longlat +datum=WGS84"); names(rast) = names(rasters_2[[i]])#
						rasters[[length(rasters)+1]] = rast#
					}#
				# rast = crop(human_pop_density, e_2); res(rast) = res(rasters_1[[1]]); extent(rast) = extent(rasters_1[[1]])#
				# crs(rast) = CRS("+proj=longlat +datum=WGS84"); rasters[[length(rasters)+1]] = rast # to add human pop. density#
				for (i in 1:length(rasters1_to_select))#
					{#
						rast1 = rasters[[i]]; rast2 = rasters_2[[1]]; rast1[is.na(rast2[])] = NA; rasters[[i]] = rast1#
					}#
				variables = rep(NA, length(rasters))#
				for (i in 1:length(rasters)) variables[i] = names(rasters[[i]])#
				rasters_stacks = stack(rasters)#
			}#
		observations = observations_list[[h]]#
		extractions = matrix(nrow=dim(observations)[1], ncol=length(rasters)); colnames(extractions) = variables#
		correlations = matrix(nrow=length(rasters), ncol=length(rasters)); row.names(correlations) = variables #
		for (i in 1:length(rasters)) extractions[,names(rasters[[i]])] = extract(rasters[[i]], observations)#
		for (i in 1:length(rasters))#
			{#
				for (j in 1:i)#
					{#
						correlations[i,j] = cor(extractions[,i],extractions[,j]); correlations[j,i] = correlations[i,j]#
					}#
			}#
		for (i in 2:length(rasters)) # second sanity check...#
			{#
				for (j in 1:(i-1))#
					{#
						if ((!is.na(correlations[i,j]))&(abs(correlations[i,j]) >= 0.7))#
							{#
								cat(paste("    r >= 0.7 - variable ",i," - variable ",j)); cat("\n")#
							}#
					}#
			}#
	}#
#
# 3. Preparing the human population density and null rasters
if (resolution == "04") human_pop_density = decreaseResolution(crop(raster("Human_pop_density.tif"), e_1), R=5)#
if (resolution == "16") human_pop_density = decreaseResolution(crop(raster("Human_pop_density.tif"), e_1), R=20)#
names(human_pop_density) = "human_pop_density"; writeRaster(human_pop_density, "Human_pop_density.asc", overwrite=T)#
human_pop_density[human_pop_density[]<0] = 0#
human_pop_density_log = human_pop_density; human_pop_density[] = log(human_pop_density[]+1)#
rast = crop(human_pop_density, e_2); res(rast) = res(rasters_1[[1]]); extent(rast) = extent(rasters_1[[1]])#
crs(rast) = CRS("+proj=longlat +datum=WGS84"); human_pop_density = rast#
rast = crop(human_pop_density_log, e_2); res(rast) = res(rasters_1[[1]]); extent(rast) = extent(rasters_1[[1]])#
crs(rast) = CRS("+proj=longlat +datum=WGS84"); human_pop_density_log = rast#
null_raster = human_pop_density; null_raster[!is.na(null_raster[])] = 1
# system("R CMD javareconf"); # rJava_0.9-10.tar.gz doesn't work...#
# install.packages("rJava_0.9-9.tar.gz", repos=NULL, type="source")#
# install.packages("dismo_1.1-4.tar.gz", repos=NULL, type="source")#
#
dyn.load("/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/server/libjvm.dylib") # MacBook Simon#
# dyn.load("/Library/Java/JavaVirtualMachines/jdk1.8.0_102.jdk/Contents/Home/jre/lib/server/libjvm.dylib") # MacPro Simon#
library(raster); library(fields); library(RColorBrewer); library(dismo); library(rJava); library(gbm); library(geosphere); library(rgdal); library(pgirmess)#
options(java.parameters="-Xmx15000m"); source("decreaseResolution.r"); source("landCoverRasters.r")#
#
datasetsDirectory = "Bombus_observations_2"#
resolution = "16"; # resolution = "04"#
e_1 = extent(-19, 88, 19, 82); e_2 = extent(-15, 84, 23, 78)#
subsampling_adjacent_cells = TRUE; background_cell = TRUE#
background_mask = FALSE; human_pop_density_bias = FALSE#
cols = rev(colorRampPalette(brewer.pal(11,"RdYlBu"))(121)[11:101])#
plotWidth = 7.0; plotHeight = 6.2#
datasets = list.files(datasetsDirectory); # datasets = datasets[40]#
datasets = gsub(".csv","",datasets[which(grepl(".csv",datasets))])#
#
# 1. Preparing the environmental rasters#
#
	# 1.1. Cropping the WorldClim 2.0 raster files (source: http://worldclim.org/bioclim)#
#
bioclimatic_variables = as.character(read.csv("Bioclimatic_variables.csv",header=T)[,"short_name"])#
files = list.files("WorldClim_2.0_rasters"); rasters_1 = list(); c = 0#
for (i in 1:length(files))#
	{#
		if ((grepl(".tif",files[i]) == TRUE)&(!file.exists(paste0("WorldClim_2.0_rasters/",gsub(".tif",paste0("_",resolution,".asc"),gsub("_2.5m","",files[i]))))))#
			{#
				rast = crop(raster(paste0("WorldClim_2.0_rasters/",files[i])),e_1)#
				if (resolution == "16") rast = decreaseResolution(rast, 4)#
				writeRaster(rast, paste0("WorldClim_2.0_rasters/",gsub(".tif",paste0("_",resolution,".asc"),gsub("_2.5m","",files[i]))))#
				c = c+1; rast = raster(paste0("WorldClim_2.0_rasters/",files[i])); id = unlist(strsplit(files[i],"_"))[length(unlist(strsplit(files[i],"_")))]#
				names(rast) = bioclimatic_variables[as.numeric(gsub(".tif","",id))]; rasters_1[[c]] = rast#
			}	else		{#
				if (grepl(paste0("_",resolution,".asc"),files[i]) == TRUE)#
					{#
						c = c+1; rast = raster(paste0("WorldClim_2.0_rasters/",files[i])); id = unlist(strsplit(files[i],"_"))[length(unlist(strsplit(files[i],"_")))-1]#
						names(rast) = bioclimatic_variables[as.numeric(gsub(".asc","",id))]; crs(rast) = CRS("+proj=longlat +datum=WGS84"); rasters_1[[c]] = rast#
					}#
			}#
	}#
#
	# 1.2. Preparing the land cover variables (source: https://lpdaac.usgs.gov/dataset_discovery/modis/modis_products_table/mcd12q1)#
#
rasters_2 = list(); land_cover_variables = c("barren_vegetation","closed_shrubland","croplands","deciduous_broadleaf_forest",#
								"deciduous_needleleaf_forest", "evergreen_broadleaf_forest","evergreen_needleleaf_forest","grasslands",#
								"mixed_forests","open_shrublands","savannas","snow_ice","urban_areas","wetlands","woody_savannas")#
if (!file.exists(paste0("Land_cover_rasters/CL_",land_cover_variables[1],"_",resolution,".asc")))#
	{#
		cover_land = crop(raster("IGBP_land_cover.tif"), e_1)#
		if (resolution == "04") landCoverRasters(rast=cover_land, R=5)#
		if (resolution == "16") landCoverRasters(rast=cover_land, R=20)#
	}#
for (i in 1:length(land_cover_variables))#
	{#
		rast = raster(paste0("Land_cover_rasters/CL_",land_cover_variables[i],"_",resolution,".asc"))#
		names(rast) = land_cover_variables[i]; rasters_2[[i]] = rast#
		# print(c(i, length(unique(extract(rast,observations)))))#
	}#
#
	# 1.3. Preparing the Natural Earth background raster (visualisation only)#
#
background = crop(raster("Natural_Earth_GIS_files/Gray_background.tif"), e_1); background[background[]==106] = NA; r = background#
cols_background = colorRampPalette(c("grey","white"),bias=1)(max(r[],na.rm=T)-min(r[],na.rm=T))[1:(max(r[],na.rm=T)-min(r[],na.rm=T))]#
#
# 2. Variables selection based on pairwise correlations#
#
observations_list = list(); N_tot_1 = 0; N_tot_2 = 0#
species_information = read.csv("species_information.csv", header=T)#
# landPolygons = crop(shapefile("World_land_polygons/World_land_polygons.shp"), e_1)#
# writeOGR(landPolygons, dsn="World_land_polygons", layer="Europe_land_polygons", driver="ESRI Shapefile")#
landPolygons_light = rgeos::gSimplify(shapefile("World_land_polygons/Europe_land_polygons.shp"), 0.1)#
plot(landPolygons_light, lwd=0.2, col="gray90", border=NA)
h=3
observations = read.csv(paste0(datasetsDirectory,"/",datasets[h],".csv"), header=T)#
		N_tot_1 = N_tot_1 + dim(observations)[1]#
		observations = unique(observations[,c("longitude","latitude")])#
		N_tot_2 = N_tot_2 + dim(observations)[1]#
		observations = observations[!is.na(extract(rasters_1[[1]], observations)),]#
		observations = observations[!is.na(extract(rasters_2[[1]], observations)),]#
		observations_list[[h]] = observations; cat(datasets[h]); cat("\n")#
		if (h == 1)#
			{#
				xmin = min(observations[,1]); xmax = max(observations[,1])#
				ymin = min(observations[,2]); ymax = max(observations[,2])#
			}	else		{#
				if (xmin > min(observations[,1])) xmin = min(observations[,1])#
				if (xmax < max(observations[,1])) xmax = max(observations[,1])#
				if (ymin > min(observations[,2])) ymin = min(observations[,2])#
				if (ymax < max(observations[,2])) ymax = max(observations[,2])#
			}
hull = chull(observations); hull = c(hull,hull[1])#
		p = Polygon(observations[hull,]); ps = Polygons(list(p),1)#
		sps = SpatialPolygons(list(ps)); crs(sps) = crs(landPolygons)#
		range = intersect(sps, landPolygons_light); plot(range, add=T, col="red")
hull = chull(observations); hull = c(hull,hull[1])#
		p = Polygon(observations[hull,]); ps = Polygons(list(p),1)#
		sps = SpatialPolygons(list(ps)); crs(sps) = crs(landPolygons_light)#
		range = intersect(sps, landPolygons_light); plot(range, add=T, col="red")
observations_list = list(); N_tot_1 = 0; N_tot_2 = 0#
species_information = read.csv("species_information.csv", header=T)#
# landPolygons = crop(shapefile("World_land_polygons/World_land_polygons.shp"), e_1)#
# writeOGR(landPolygons, dsn="World_land_polygons", layer="Europe_land_polygons", driver="ESRI Shapefile")#
landPolygons_light = rgeos::gSimplify(shapefile("World_land_polygons/Europe_land_polygons.shp"), 0.1)#
plot(landPolygons_light, lwd=0.2, col="gray90", border=NA)#
for (h in 1:length(datasets))#
	{#
		observations = read.csv(paste0(datasetsDirectory,"/",datasets[h],".csv"), header=T)#
		N_tot_1 = N_tot_1 + dim(observations)[1]#
		observations = unique(observations[,c("longitude","latitude")])#
		N_tot_2 = N_tot_2 + dim(observations)[1]#
		observations = observations[!is.na(extract(rasters_1[[1]], observations)),]#
		observations = observations[!is.na(extract(rasters_2[[1]], observations)),]#
		observations_list[[h]] = observations; cat(datasets[h]); cat("\n")#
		if (h == 1)#
			{#
				xmin = min(observations[,1]); xmax = max(observations[,1])#
				ymin = min(observations[,2]); ymax = max(observations[,2])#
			}	else		{#
				if (xmin > min(observations[,1])) xmin = min(observations[,1])#
				if (xmax < max(observations[,1])) xmax = max(observations[,1])#
				if (ymin > min(observations[,2])) ymin = min(observations[,2])#
				if (ymax < max(observations[,2])) ymax = max(observations[,2])#
			}#
		hull = chull(observations); hull = c(hull,hull[1])#
		p = Polygon(observations[hull,]); ps = Polygons(list(p),1)#
		sps = SpatialPolygons(list(ps)); crs(sps) = crs(landPolygons_light)#
		range = intersect(sps, landPolygons_light); plot(range, add=T, col="red")#
		index = which(species_information[,"species"]==datasets[h])#
		species_information[index,"area_km2"] = areaPolygon(range)/1000000#
	}#
write.csv(species_information, "species_information.csv", quote=F, row.names=F)
h
observations = read.csv(paste0(datasetsDirectory,"/",datasets[h],".csv"), header=T)#
		N_tot_1 = N_tot_1 + dim(observations)[1]#
		observations = unique(observations[,c("longitude","latitude")])#
		N_tot_2 = N_tot_2 + dim(observations)[1]#
		observations = observations[!is.na(extract(rasters_1[[1]], observations)),]#
		observations = observations[!is.na(extract(rasters_2[[1]], observations)),]#
		observations_list[[h]] = observations; cat(datasets[h]); cat("\n")
if (h == 1)#
			{#
				xmin = min(observations[,1]); xmax = max(observations[,1])#
				ymin = min(observations[,2]); ymax = max(observations[,2])#
			}	else		{#
				if (xmin > min(observations[,1])) xmin = min(observations[,1])#
				if (xmax < max(observations[,1])) xmax = max(observations[,1])#
				if (ymin > min(observations[,2])) ymin = min(observations[,2])#
				if (ymax < max(observations[,2])) ymax = max(observations[,2])#
			}
hull = chull(observations); hull = c(hull,hull[1])
p = Polygon(observations[hull,]); ps = Polygons(list(p),1)
sps = SpatialPolygons(list(ps)); crs(sps) = crs(landPolygons_light)
range = intersect(sps, landPolygons_light); plot(range, add=T, col="red")
index = which(species_information[,"species"]==datasets[h])
index
species_information[index,"area_km2"] = areaPolygon(range)/1000000
index
species_information[index,"area_km2"]
areaPolygon(range)/1000000
range
range = intersect(sps, landPolygons_light); plot(range, add=T, col="green3")
hist(areaPolygon(range)/1000000)
max(areaPolygon(range)/1000000)
plot(landPolygons_light, lwd=0.2, col="gray90", border=NA)#
for (h in 1:length(datasets))#
	{#
		observations = read.csv(paste0(datasetsDirectory,"/",datasets[h],".csv"), header=T)#
		N_tot_1 = N_tot_1 + dim(observations)[1]#
		observations = unique(observations[,c("longitude","latitude")])#
		N_tot_2 = N_tot_2 + dim(observations)[1]#
		observations = observations[!is.na(extract(rasters_1[[1]], observations)),]#
		observations = observations[!is.na(extract(rasters_2[[1]], observations)),]#
		observations_list[[h]] = observations; cat(datasets[h]); cat("\n")#
		if (h == 1)#
			{#
				xmin = min(observations[,1]); xmax = max(observations[,1])#
				ymin = min(observations[,2]); ymax = max(observations[,2])#
			}	else		{#
				if (xmin > min(observations[,1])) xmin = min(observations[,1])#
				if (xmax < max(observations[,1])) xmax = max(observations[,1])#
				if (ymin > min(observations[,2])) ymin = min(observations[,2])#
				if (ymax < max(observations[,2])) ymax = max(observations[,2])#
			}#
		hull = chull(observations); hull = c(hull,hull[1])#
		p = Polygon(observations[hull,]); ps = Polygons(list(p),1)#
		sps = SpatialPolygons(list(ps)); crs(sps) = crs(landPolygons_light)#
		range = intersect(sps, landPolygons_light); plot(range, add=T, col="green3")#
		index = which(species_information[,"species"]==datasets[h])#
		species_information[index,"area_km2"] = sum(areaPolygon(range)/1000000)#
	}#
write.csv(species_information, "species_information.csv", quote=F, row.names=F)
datasets
h=47
plot(landPolygons_light, lwd=0.2, col="gray90", border=NA)
observations = read.csv(paste0(datasetsDirectory,"/",datasets[h],".csv"), header=T)#
		N_tot_1 = N_tot_1 + dim(observations)[1]#
		observations = unique(observations[,c("longitude","latitude")])#
		N_tot_2 = N_tot_2 + dim(observations)[1]#
		observations = observations[!is.na(extract(rasters_1[[1]], observations)),]#
		observations = observations[!is.na(extract(rasters_2[[1]], observations)),]#
		observations_list[[h]] = observations; cat(datasets[h]); cat("\n")#
		if (h == 1)#
			{#
				xmin = min(observations[,1]); xmax = max(observations[,1])#
				ymin = min(observations[,2]); ymax = max(observations[,2])#
			}	else		{#
				if (xmin > min(observations[,1])) xmin = min(observations[,1])#
				if (xmax < max(observations[,1])) xmax = max(observations[,1])#
				if (ymin > min(observations[,2])) ymin = min(observations[,2])#
				if (ymax < max(observations[,2])) ymax = max(observations[,2])#
			}#
		hull = chull(observations); hull = c(hull,hull[1])#
		p = Polygon(observations[hull,]); ps = Polygons(list(p),1)#
		sps = SpatialPolygons(list(ps)); crs(sps) = crs(landPolygons_light)#
		range = intersect(sps, landPolygons_light); plot(range, add=T, col="green3")
index = which(species_information[,"species"]==datasets[h])
index
observations = read.csv(paste0(datasetsDirectory,"/",datasets[h],".csv"), header=T)#
		N_tot_1 = N_tot_1 + dim(observations)[1]#
		observations = unique(observations[,c("longitude","latitude")])#
		N_tot_2 = N_tot_2 + dim(observations)[1]#
		observations = observations[!is.na(extract(rasters_1[[1]], observations)),]#
		observations = observations[!is.na(extract(rasters_2[[1]], observations)),]#
		observations_list[[h]] = observations; cat(datasets[h]); cat("\n")#
		if (h == 1)#
			{#
				xmin = min(observations[,1]); xmax = max(observations[,1])#
				ymin = min(observations[,2]); ymax = max(observations[,2])#
			}	else		{#
				if (xmin > min(observations[,1])) xmin = min(observations[,1])#
				if (xmax < max(observations[,1])) xmax = max(observations[,1])#
				if (ymin > min(observations[,2])) ymin = min(observations[,2])#
				if (ymax < max(observations[,2])) ymax = max(observations[,2])#
			}#
		hull = chull(observations); hull = c(hull,hull[1])#
		p = Polygon(observations[hull,]); ps = Polygons(list(p),1)#
		sps = SpatialPolygons(list(ps)); crs(sps) = crs(landPolygons_light)#
		range = intersect(sps, landPolygons_light); plot(range, add=T, col="green3")#
		index = which(species_information[,"species"]==datasets[h])#
		species_information[index,"area_km2"] = sum(areaPolygon(range)/1000000)
write.csv(species_information, "species_information.csv", quote=F, row.names=F)
species_information = read.csv("species_information.csv", header=T)
observations = read.csv(paste0(datasetsDirectory,"/",datasets[h],".csv"), header=T)#
		N_tot_1 = N_tot_1 + dim(observations)[1]#
		observations = unique(observations[,c("longitude","latitude")])#
		N_tot_2 = N_tot_2 + dim(observations)[1]#
		observations = observations[!is.na(extract(rasters_1[[1]], observations)),]#
		observations = observations[!is.na(extract(rasters_2[[1]], observations)),]#
		observations_list[[h]] = observations; cat(datasets[h]); cat("\n")#
		if (h == 1)#
			{#
				xmin = min(observations[,1]); xmax = max(observations[,1])#
				ymin = min(observations[,2]); ymax = max(observations[,2])#
			}	else		{#
				if (xmin > min(observations[,1])) xmin = min(observations[,1])#
				if (xmax < max(observations[,1])) xmax = max(observations[,1])#
				if (ymin > min(observations[,2])) ymin = min(observations[,2])#
				if (ymax < max(observations[,2])) ymax = max(observations[,2])#
			}#
		hull = chull(observations); hull = c(hull,hull[1])#
		p = Polygon(observations[hull,]); ps = Polygons(list(p),1)#
		sps = SpatialPolygons(list(ps)); crs(sps) = crs(landPolygons_light)#
		range = intersect(sps, landPolygons_light); plot(range, add=T, col="green3")#
		index = which(species_information[,"species"]==datasets[h])#
		species_information[index,"area_km2"] = sum(areaPolygon(range)/1000000)
write.csv(species_information, "species_information.csv", quote=F, row.names=F)
species_information = read.csv("species_information.csv", header=T)
observations = read.csv(paste0(datasetsDirectory,"/",datasets[h],".csv"), header=T)#
		N_tot_1 = N_tot_1 + dim(observations)[1]#
		observations = unique(observations[,c("longitude","latitude")])#
		N_tot_2 = N_tot_2 + dim(observations)[1]#
		observations = observations[!is.na(extract(rasters_1[[1]], observations)),]#
		observations = observations[!is.na(extract(rasters_2[[1]], observations)),]#
		observations_list[[h]] = observations; cat(datasets[h]); cat("\n")#
		if (h == 1)#
			{#
				xmin = min(observations[,1]); xmax = max(observations[,1])#
				ymin = min(observations[,2]); ymax = max(observations[,2])#
			}	else		{#
				if (xmin > min(observations[,1])) xmin = min(observations[,1])#
				if (xmax < max(observations[,1])) xmax = max(observations[,1])#
				if (ymin > min(observations[,2])) ymin = min(observations[,2])#
				if (ymax < max(observations[,2])) ymax = max(observations[,2])#
			}#
		hull = chull(observations); hull = c(hull,hull[1])#
		p = Polygon(observations[hull,]); ps = Polygons(list(p),1)#
		sps = SpatialPolygons(list(ps)); crs(sps) = crs(landPolygons_light)#
		range = intersect(sps, landPolygons_light); plot(range, add=T, col="green3")#
		index = which(species_information[,"species"]==datasets[h])#
		species_information[index,"area_km2"] = sum(areaPolygon(range)/1000000)
species_information = read.csv("species_information.csv", header=T)
observations = read.csv(paste0(datasetsDirectory,"/",datasets[h],".csv"), header=T)#
		N_tot_1 = N_tot_1 + dim(observations)[1]#
		observations = unique(observations[,c("longitude","latitude")])#
		N_tot_2 = N_tot_2 + dim(observations)[1]#
		observations = observations[!is.na(extract(rasters_1[[1]], observations)),]#
		observations = observations[!is.na(extract(rasters_2[[1]], observations)),]#
		observations_list[[h]] = observations; cat(datasets[h]); cat("\n")#
		if (h == 1)#
			{#
				xmin = min(observations[,1]); xmax = max(observations[,1])#
				ymin = min(observations[,2]); ymax = max(observations[,2])#
			}	else		{#
				if (xmin > min(observations[,1])) xmin = min(observations[,1])#
				if (xmax < max(observations[,1])) xmax = max(observations[,1])#
				if (ymin > min(observations[,2])) ymin = min(observations[,2])#
				if (ymax < max(observations[,2])) ymax = max(observations[,2])#
			}#
		hull = chull(observations); hull = c(hull,hull[1])#
		p = Polygon(observations[hull,]); ps = Polygons(list(p),1)#
		sps = SpatialPolygons(list(ps)); crs(sps) = crs(landPolygons_light)#
		range = intersect(sps, landPolygons_light); plot(range, add=T, col="green3")#
		index = which(species_information[,"species"]==datasets[h])
index
species_information[index,"area_km2"] = sum(areaPolygon(range)/1000000)
species_information[index,"area_km2"]
write.csv(species_information, "species_information.csv", quote=F, row.names=F)
observations_list = list(); N_tot_1 = 0; N_tot_2 = 0#
species_information = read.csv("species_information.csv", header=T)#
# landPolygons = crop(shapefile("World_land_polygons/World_land_polygons.shp"), e_1)#
# writeOGR(landPolygons, dsn="World_land_polygons", layer="Europe_land_polygons", driver="ESRI Shapefile")#
landPolygons_light = rgeos::gSimplify(shapefile("World_land_polygons/Europe_land_polygons.shp"), 0.1)#
plot(landPolygons_light, lwd=0.2, col="gray90", border=NA)#
for (h in 1:length(datasets))#
	{#
		observations = read.csv(paste0(datasetsDirectory,"/",datasets[h],".csv"), header=T)#
		N_tot_1 = N_tot_1 + dim(observations)[1]#
		observations = unique(observations[,c("longitude","latitude")])#
		N_tot_2 = N_tot_2 + dim(observations)[1]#
		observations = observations[!is.na(extract(rasters_1[[1]], observations)),]#
		observations = observations[!is.na(extract(rasters_2[[1]], observations)),]#
		observations_list[[h]] = observations; cat(datasets[h]); cat("\n")#
		if (h == 1)#
			{#
				xmin = min(observations[,1]); xmax = max(observations[,1])#
				ymin = min(observations[,2]); ymax = max(observations[,2])#
			}	else		{#
				if (xmin > min(observations[,1])) xmin = min(observations[,1])#
				if (xmax < max(observations[,1])) xmax = max(observations[,1])#
				if (ymin > min(observations[,2])) ymin = min(observations[,2])#
				if (ymax < max(observations[,2])) ymax = max(observations[,2])#
			}#
		hull = chull(observations); hull = c(hull,hull[1])#
		p = Polygon(observations[hull,]); ps = Polygons(list(p),1)#
		sps = SpatialPolygons(list(ps)); crs(sps) = crs(landPolygons_light)#
		range = intersect(sps, landPolygons_light); plot(range, add=T, col="green3")#
		index = which(species_information[,"species"]==datasets[h])#
		species_information[index,"area_km2"] = round(sum(areaPolygon(range)/1000000))#
	}#
write.csv(species_information, "species_information.csv", quote=F, row.names=F)
# system("R CMD javareconf"); # rJava_0.9-10.tar.gz doesn't work...#
# install.packages("rJava_0.9-9.tar.gz", repos=NULL, type="source")#
# install.packages("dismo_1.1-4.tar.gz", repos=NULL, type="source")#
#
dyn.load("/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/server/libjvm.dylib") # MacBook Simon#
# dyn.load("/Library/Java/JavaVirtualMachines/jdk1.8.0_102.jdk/Contents/Home/jre/lib/server/libjvm.dylib") # MacPro Simon#
library(raster); library(fields); library(RColorBrewer); library(dismo); library(rJava); library(gbm); library(geosphere); library(rgdal); library(pgirmess)#
options(java.parameters="-Xmx15000m"); source("decreaseResolution.r"); source("landCoverRasters.r")#
#
datasetsDirectory = "Bombus_observations_2"#
resolution = "16"; # resolution = "04"#
e_1 = extent(-19, 88, 19, 82); e_2 = extent(-15, 84, 23, 78)#
subsampling_adjacent_cells = TRUE; background_cell = TRUE#
background_mask = FALSE; human_pop_density_bias = FALSE#
cols = rev(colorRampPalette(brewer.pal(11,"RdYlBu"))(121)[11:101])#
plotWidth = 7.0; plotHeight = 6.2#
datasets = list.files(datasetsDirectory); # datasets = datasets[40]#
datasets = gsub(".csv","",datasets[which(grepl(".csv",datasets))])#
#
# 1.
system("R CMD javareconf"); # rJava_0.9-10.tar.gz doesn't work...
install.packages("rJava_0.9-9.tar.gz", repos=NULL, type="source")
dyn.load("/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/server/libjvm.dylib") # MacBook Simon#
# dyn.load("/Library/Java/JavaVirtualMachines/jdk1.8.0_102.jdk/Contents/Home/jre/lib/server/libjvm.dylib") # MacPro Simon#
library(raster); library(fields); library(RColorBrewer); library(dismo); library(rJava); library(gbm); library(geosphere); library(rgdal); library(pgirmess)#
options(java.parameters="-Xmx15000m"); source("decreaseResolution.r"); source("landCoverRasters.r")
library(raster); library(fields); library(RColorBrewer);
library(gbm); library(geosphere); library(rgdal); library(pgirmess)
install.packages("gbm")
library(gbm); library(geosphere); library(rgdal); library(pgirmess)
install.packages("pgirmess")
library(raster); library(fields); library(RColorBrewer); library(dismo); library(rJava); library(gbm); library(geosphere); library(rgdal); library(pgirmess)
install.packages("rJava_0.9-9.tar.gz", repos=NULL, type="source")
library(rJava)
install.packages("dismo_1.1-4.tar.gz", repos=NULL, type="source")
system("R CMD javareconf"); # rJava_0.9-10.tar.gz doesn't work...
install.packages("rJava_0.9-9.tar.gz", repos=NULL, type="source")
install.packages("dismo_1.1-4.tar.gz", repos=NULL, type="source")#
#
# dyn.load("/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/server/libjvm.dylib") # MacBook Simon
install.packages("rJava")
library(raster); library(fields); library(RColorBrewer); library(dismo); library(rJava); library(gbm); library(geosphere); library(rgdal); library(pgirmess)#
options(java.parameters="-Xmx15000m"); source("decreaseResolution.r"); source("landCoverRasters.r")
library(rJava)
system("R CMD javareconf"); # rJava_0.9-10.tar.gz doesn't work...
install.packages("rJava_0.9-9.tar.gz", repos=NULL, type="source")
library(raster); library(fields); library(RColorBrewer); library(dismo); library(rJava); library(gbm); library(geosphere); library(rgdal); library(pgirmess)
system("sudo R CMD javareconf"); # rJava_0.9-10.tar.gz didn't work before
# system("R CMD javareconf"); # rJava_0.9-10.tar.gz didn't work before
system("R CMD javareconf"); # rJava_0.9-10.tar.gz didn't work before
library(raster); library(fields); library(RColorBrewer); library(dismo); library(rJava); library(gbm); library(geosphere); library(rgdal); library(pgirmess)
dyn.load("/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/server/libjvm.dylib") # MacBook Simon
library(raster); library(fields); library(RColorBrewer); library(dismo); library(rJava); library(gbm); library(geosphere); library(rgdal); library(pgirmess)
dyn.load("/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/server/libjvm.dylib") # MacBook Simon
library(raster); library(fields); library(RColorBrewer); library(dismo); library(rJava); library(gbm); library(geosphere); library(rgdal); library(pgirmess)
dyn.load("/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/server/libjvm.dylib") # MacBook Simon
remove.packages("rJava")
install.packages("rJava_0.9-9.tar.gz", repos=NULL, type="source")
system("R CMD javareconf")
system("R CMD javareconf"); # rJava_0.9-10.tar.gz didn't work before
install.packages("rJava_0.9-9.tar.gz", repos=NULL, type="source")
install.packages("rJava")
dyn.load("/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/server/libjvm.dylib") # MacBook Simon
library(rJava)
dyn.load("/Library/Java/JavaVirtualMachines/jdk1.8.0_151.jdk/Contents/Home/jre/lib/server/libjvm.dylib") # MacBook Simon
library(rJava)
install.packages("devtools")
library(devtools)
install_github("sdellicour/seraphim/macOS")
install_github("sdellicour/seraphim/unix_OS")
library(seraphim)
remove.packages("seraphim")
install.packages("devtools"); library(devtools)#
install_github("sdellicour/seraphim/unix_OS")#
library(seraphim)
logMLE1 = -12834.317605730235 # for RRW (logN)
logMLE2 = -12856.611381507528 # for DRW
logMLE3 = -12842.860284601575 # for DRW (latitude only)
BF12 = exp(logMLE1/logMLE2)
BF12
BF21 = exp(logMLE2/logMLE1)
BF21
exp(logMLE2)
exp(logMLE1)
exp(logMLE2)
logMLE1/logMLE2
BF12 = exp(logMLE1-logMLE2)
BF12
logMLE1-logMLE2
BF12 = logMLE1-logMLE2
BF12
?exp
e^3
2.71^(logMLE1-logMLE2)
exp(logMLE1-logMLE2)
exp(logMLE1)/exp(logMLE2)
exp(logMLE2)
exp(logMLE1)
lubridate
library(lubridate)
date_decimal(2020.18579234973)
date_decimal(2020.16393442623)
date_decimal(2020.17759562842)
date_decimal(2020.17486338798)
date_decimal(2020.18579234973)
date_decimal(2020.19945355191)
date_decimal(2020.19945355)
date_decimal(2020.20765027322)
date_decimal(2020.2650273224)
library(ape)
?ace
install.packages("plotly")
us_cities = read.csv("https://raw.githubusercontent.com/plotly/datasets/master/us-cities-top-1k.csv")
fig <- us_cities
fig <- fig %>%#
  plot_ly(#
    lat = ~lat,#
    lon = ~lon,#
    marker = list(color = "fuchsia"),#
    type = 'scattermapbox',#
    hovertext = us_cities[,"City"])
fig <- fig#
  plot_ly(#
    lat = ~lat,#
    lon = ~lon,#
    marker = list(color = "fuchsia"),#
    type = 'scattermapbox',#
    hovertext = us_cities[,"City"])
library(plotly)
fig <- fig %>%#
  plot_ly(#
    lat = ~lat,#
    lon = ~lon,#
    marker = list(color = "fuchsia"),#
    type = 'scattermapbox',#
    hovertext = us_cities[,"City"])
fig <- fig %>%#
  layout(#
    mapbox = list(#
      style = 'open-street-map',#
      zoom =2.5,#
      center = list(lon = -88, lat = 34)))
fig
?shapefile
??shapefile
??readOGR
# TO DO:#
	# - analyses based on the new tree#
	# - 4 snapshots (+ 4 snapshots for the number of introductions/UTLA): 05/11, 01/12, 20/12#
	# - explore the possibility to generate edges bundle?#
	# - generate RData with list of daily matrices of dispersal events among postcode or UTLA#
#
library(diagram)#
library(lubridate)#
library(seraphim)#
library(treeio)#
library(viridis)#
#
analysis_date = "270221"#
writingFiles = FALSE; savingPlots = FALSE#
#
postcodes = shapefile("Shapefiles_study_area/England_postcode_districts.shp"); crs(postcodes) = CRS("+init=epsg:27700")#
UTLAs = spTransform(shapefile("Shapefiles_study_area/UTLA_administrative_areas.shp"), crs(postcodes))#
pop = projectRaster(raster("WorldPop_pop_raster.tif"), crs=crs(postcodes)); pop[] = log(pop[])
# Crée un vecteur avec 50 valeurs tirées d'une distribution normale#
	myValues = rnorm(50, mean=10, sd=3)#
	# Pour afficher ces valeurs, simplement rentrer le nom du vecteur#
	myvalues
myValues
hist(myValues, main="")
hist(myValues, main=" », breaks=15)
hist(myValues, main=" », breaks=15)))"
# Affiche un histogramme des valeurs du vecteur myValues#
hist(myValues, main="", breaks=15)
library(dismo)
?gbm.step
library(lubridate)
date_decimal(2022.14520547945)
s=0.795+1.665+0.381+0.388+2.337+0.434
s
vS=c(0.795,1.665,0.381,0.388,2.337,0.434)
mean(vS)
median(vS)
?wilcox.test
library(ape)
library(rgdal)
library(rgdal)
library(rgeos)
library(raster)
admin_1 = readOGR(dsn="./admin_shapefiles", layer="admin_1_Mekong")
admin_1 = shapefile("GADM_shapefiles/GADM_1_Mekong.shp")
admin2_admin1ID = read.table("GADM_shapefiles/Admin2_admin1ID.txt", header=T)
admin_1 = shapefile("GADM_shapefiles/GADM_1_Mekong.shp")#
admin_2 = shapefile("GADM_shapefiles/GADM_1_Mekong.shp")#
admin2_admin1ID = read.table("GADM_shapefiles/Admin2_admin1ID.txt", header=T)
fasta = read.dna("H5N1_clade1.fasta", format="fasta")#
names = row.names(fasta)#
sequenceIDs = matrix(nrow=length(names), ncol=1)#
coordinates = matrix(nrow=length(names), ncol=2)#
precisions = matrix(nrow=length(names), ncol=1)#
years = matrix(nrow=length(names), ncol=1)#
for (i in 1:length(names)) {#
	sequenceIDs[i,1] = unlist(strsplit(names[i],"_"))[1]#
	coordinates[i,] = unlist(strsplit(names[i],"_"))[4:5]#
	p = unlist(strsplit(names[i],"_"))[6]#
	precisions[i,1] = as.numeric(unlist(strsplit(p,"-admin"))[2])#
	if (is.na(precisions[i,1])) precisions[j,1] = 1#
	if (precisions[i,1] == 3) precisions[i,1] = 2#
	years[i,1] = as.numeric(unlist(strsplit(names[i],"_"))[3])#
}
chickens_density = raster("Mekong_rasters/Chickens_Mekong.asc")#
ducks_density = raster("Mekong_rasters/Ducks_Mekong.asc")
chickens_density = raster("Mekong_rasters/Chickens_Mekong.asc")#
ducks_density = raster("Mekong_rasters/Ducks_Mekong.asc")
chickens_number = chickens_density*raster::area(chickens_density)#
ducks_number = ducks_density*raster::area(ducks_density)#
hosts = chickens_number#
hosts[] = hosts[]+ducks_number[]
records_all = c()#
records_list = list()#
for (year in 2003:2012) {#
	records_list[[year-2002]] = read.csv(paste("H5N1_records/H5N1_",year,".csv",sep=""), header=T)[,cbind("LON","LAT")]#
	records_all = rbind(records_all, records_list[[year-2002]])#
}
hosts_counts = c()#
records_counts_list = list()#
for (i in 1:length(admin_2@polygons)) {#
	hCounts = 0#
	for (j in 1:length(admin_2@polygons[[i]]@Polygons)) {#
		p = Polygon(coords)#
		ps = Polygons(list(p),1)#
		sps = SpatialPolygons(list(ps))#
		r = mask(crop(hosts, coords), sps)#
		hCounts = hCounts + sum(r[], na.rm=T)	#
	}#
	hosts_counts = c(hosts_counts, log(hCounts+1))	#
}
admin_2@polygons[[i]]@Polygons[[j]]@coords
hosts_counts = c()#
records_counts_list = list()#
for (i in 1:length(admin_2@polygons)) {#
	hCounts = 0#
	for (j in 1:length(admin_2@polygons[[i]]@Polygons)) {#
		admin_2@polygons[[i]]@Polygons[[j]]@coords#
		p = Polygon(coords)#
		ps = Polygons(list(p),1)#
		sps = SpatialPolygons(list(ps))#
		r = mask(crop(hosts, coords), sps)#
		hCounts = hCounts + sum(r[], na.rm=T)	#
	}#
	hosts_counts = c(hosts_counts, log(hCounts+1))	#
}
hosts_counts = c()#
records_counts_list = list()#
for (i in 1:length(admin_2@polygons)) {#
	hCounts = 0#
	for (j in 1:length(admin_2@polygons[[i]]@Polygons)) {#
		coords = admin_2@polygons[[i]]@Polygons[[j]]@coords#
		p = Polygon(coords)#
		ps = Polygons(list(p),1)#
		sps = SpatialPolygons(list(ps))#
		r = mask(crop(hosts, coords), sps)#
		hCounts = hCounts + sum(r[], na.rm=T)	#
	}#
	hosts_counts = c(hosts_counts, log(hCounts+1))	#
}
hosts_counts = c()#
records_counts_list = list()#
for (i in 1:length(admin_2@polygons)) {#
	hCounts = 0#
	for (j in 1:length(admin_2@polygons[[i]]@Polygons)) {#
		coords = admin_2@polygons[[i]]@Polygons[[j]]@coords#
		p = Polygon(coords)#
		ps = Polygons(list(p),1)#
		sps = SpatialPolygons(list(ps))#
		r = mask(crop(hosts, coords), sps)#
		hCounts = hCounts + sum(r[], na.rm=T)	#
	}#
	hosts_counts = c(hosts_counts, log(hCounts+1))	#
}
for (h in 2:length(records_list)) {#
	buffer = c()#
	for (i in 1:length(admin_2@polygons)) {#
		rCounts = 0; hCounts = 0#
		for (j in 1:length(admin_2@polygons[[i]]@Polygons)) {#
			coords = admin_2@polygons[[i]]@Polygons[[j]]@coords#
			for (k in 1:dim(records_list[[h]])[1]) {#
				if (point.in.polygon(records_list[[h]][k,1], records_list[[h]][k,2], coords[,1], coords[,2], mode.checked=FALSE) == 1) {#
					rCounts = rCounts+1#
				}#
			}#
		}#
		buffer = c(buffer, rCounts)		#
	}#
	records_counts_list[[h]] = buffer	#
}
admins = list()#
admins[[1]] = admin_1#
admins[[2]] = admin_2#
for (i in 1:dim(coordinates)[1]) {#
	admin = admins[[as.numeric(precisions[i])]]#
	sampling_coord = cbind(as.numeric(coordinates[i,1]),as.numeric(coordinates[i,2]))#
	sequenceID = sequenceIDs[i,1]#
	index = 0#
	for (j in 1:length(admin@polygons)) {#
		for (k in 1:length(admin@polygons[[j]]@Polygons)) {#
			if (point.in.polygon(sampling_coord[1], sampling_coord[2], admin@polygons[[j]]@Polygons[[k]]@coords[,1], admin@polygons[[j]]@Polygons[[k]]@coords[,2], mode.checked=FALSE) == 1) {#
				index = j#
			}#
		}#
	}#
	if ((index == 0) & (precisions[i]==2)) {#
		# print(paste("No initial administrative polygon admin-2 found for ",sequenceID,sep=""))#
		counter = 0#
		while (index == 0) {#
			if (runif(1,0,1) < 0.5) {#
				sampling_coord[1] = sampling_coord[1] - 0.001#
			}	else	{#
				sampling_coord[1] = sampling_coord[1] + 0.001#
			}#
			if (runif(1,0,1) < 0.5) {#
				sampling_coord[2] = sampling_coord[2] - 0.001#
			}	else	{#
				sampling_coord[2] = sampling_coord[2] + 0.001#
			}#
			for (j in 1:length(admin@polygons)) {#
				for (k in 1:length(admin@polygons[[j]]@Polygons)) {#
					if (point.in.polygon(sampling_coord[1], sampling_coord[2], admin@polygons[[j]]@Polygons[[k]]@coords[,1], admin@polygons[[j]]@Polygons[[k]]@coords[,2], mode.checked=FALSE) == 1) {#
						index = j#
					}#
				}#
			}#
		}#
	}#
	maxArea = 0; polIndex = 0#
	for (j in 1:length(admin@polygons[[index]]@Polygons)) {#
		if (maxArea < admin@polygons[[index]]@Polygons[[j]]@area) {#
			maxArea = admin@polygons[[index]]@Polygons[[j]]@area#
			polIndex = j#
		}#
	}#
	pol1 = admin@polygons[[index]]@Polygons[[polIndex]]#
	p = Polygon(pol1@coords); ps = Polygons(list(p),1); sps = SpatialPolygons(list(ps))#
	pol1 = sps; proj4string(pol1) = CRS("+init=epsg:4326")#
	coords = admin@polygons[[index]]@Polygons[[polIndex]]@coords#
	if (precisions[i] == 2) {#
		sink(file=paste("H5N1_polygons/",sequenceID,".kml",sep=""))#
		cat("<?xml version=\"1.0\" encoding=\"UTF-8\"?>"); cat("\n")#
		cat("<kml xmlns=\"http://earth.google.com/kml/2.2\">"); cat("\n")#
		cat(paste("\t<polygon id=\"",paste(sequenceID,sep="_"),"\" samplingProbability=\"",1,"\">",sep="")); cat("\n")#
		cat("\t\t<coordinates>"); cat("\n")#
		for (j in 1:dim(coords)[1]) {#
			cat(paste("\t\t\t",coords[j,2],",",coords[j,1],",0",sep="")); cat("\n")#
		}#
		cat("\t\t</coordinates>"); cat("\n")#
		cat("\t</polygon>"); cat("\n")#
		cat("</kml>"); cat("\n")#
		sink(NULL)#
	}#
	if (precisions[i] == 1) {#
		indices = which(admin2_admin1ID == index)#
		year_index = years[i,1]-2002#
		records_selected = records_counts_list[[year_index]]#
		oRecords = records_counts[indices]#
		hRecords = hosts_counts[indices]#
		records = c()#
		if (sum(oRecords) > 0) {#
			records = oRecords#
		}	else	{#
			records = hRecords#
		}#
		pols2_not_included = c()#
		sink(file=paste("H5N1_polygons/",sequenceID,".kml",sep=""))#
		cat("<?xml version=\"1.0\" encoding=\"UTF-8\"?>"); cat("\n")#
		cat("<kml xmlns=\"http://earth.google.com/kml/2.2\">"); cat("\n")#
		firstPlot = TRUE#
		for (j in 1:length(indices)) {#
			fValue = records[j]/sum(records)						#
			if (fValue > 0) {#
				maxArea = 0; polIndex2 = 0#
				for (k in 1:length(admin_2@polygons[[indices[j]]]@Polygons)) {#
					if (maxArea < admin_2@polygons[[indices[j]]]@Polygons[[k]]@area) {#
						maxArea = admin_2@polygons[[indices[j]]]@Polygons[[k]]@area#
						polIndex2 = k#
					}#
				}#
				coords = admin_2@polygons[[indices[j]]]@Polygons[[polIndex2]]@coords#
				cat(paste("\t<polygon id=\"",paste(sequenceID,j,sep="_"),"\" samplingProbability=\"",fValue,"\">",sep=""))#
				cat("\n")#
				cat("\t\t<coordinates>"); cat("\n")#
				for (l in 1:dim(coords)[1]) {#
					cat(paste("\t\t\t",coords[l,2],",",coords[l,1],",0",sep="")); cat("\n")#
				}#
				cat("\t\t</coordinates>"); cat("\n")#
				cat("\t</polygon>"); cat("\n")#
				pol2 = admin_2@polygons[[indices[j]]]@Polygons[[polIndex2]]#
				p = Polygon(pol2@coords); ps = Polygons(list(p),1); sps = SpatialPolygons(list(ps)); #
				pol2 = sps; proj4string(pol2) = CRS("+init=epsg:4326")#
				if (gIntersects(pol1, pol2) == TRUE) {#
					pol3 = gIntersection(pol1, pol2)#
					if (class(pol3) == "SpatialPolygons") {#
						area2 = pol2@polygons[[1]]@area#
						area3 = pol3@polygons[[1]]@area#
						if (area3 < (0.5*area2)) {#
							pols2_not_included = c(pols2_not_included, j)#
						}#
					}#
				}#
			}#
		}#
		cat("</kml>"); cat("\n")#
		sink(NULL)#
	}#
}
year_index
records_counts_list[[year_index]]
length(admin2_admin1ID)
admin2_admin1ID
dim(admin2_admin1ID)
str(hosts_counts)
str(admin2_admin1ID)
indices = which(admin2_admin1ID == index)
indices
indices = which(admin2_admin1ID == index)#
		year_index = years[i,1]-2002#
		records_selected = records_counts_list[[year_index]]#
		oRecords = records_counts[indices]#
		hRecords = hosts_counts[indices]
hRecords
hosts_counts
length(admin_2@polygons)
length(buffer)
admin2_admin1ID = read.table("GADM_shapefiles/Admin2_admin1ID.txt", header=T)
admin2_admin1ID
install.packages("ape"); library(ape)#
install.packages("rgdal"); library(rgdal)#
install.packages("rgeos"); library(rgeos)#
install.packages("raster"); library(raster)#
#
# Step 2: loading admin-1 and admin-2 borders (shapefiles)#
#
admin_1 = shapefile("GADM_shapefiles/GADM_1_Mekong.shp")#
admin_2 = shapefile("GADM_shapefiles/GADM_2_Mekong.shp")#
admin2_admin1ID = read.table("GADM_shapefiles/Admin2_admin1ID.txt", header=T)#
#
# Step 3: reading sampling data associated with each sequence from a fasta alignment#
#
fasta = read.dna("H5N1_clade1.fasta", format="fasta")#
names = row.names(fasta)#
sequenceIDs = matrix(nrow=length(names), ncol=1)#
coordinates = matrix(nrow=length(names), ncol=2)#
precisions = matrix(nrow=length(names), ncol=1)#
years = matrix(nrow=length(names), ncol=1)#
for (i in 1:length(names)) {#
	sequenceIDs[i,1] = unlist(strsplit(names[i],"_"))[1]#
	coordinates[i,] = unlist(strsplit(names[i],"_"))[4:5]#
	p = unlist(strsplit(names[i],"_"))[6]#
	precisions[i,1] = as.numeric(unlist(strsplit(p,"-admin"))[2])#
	if (is.na(precisions[i,1])) precisions[j,1] = 1#
	if (precisions[i,1] == 3) precisions[i,1] = 2#
	years[i,1] = as.numeric(unlist(strsplit(names[i],"_"))[3])#
}#
#
# Step 4: loading hosts (chicken and duck) density rasters#
#
chickens_density = raster("Mekong_rasters/Chickens_Mekong.asc")#
ducks_density = raster("Mekong_rasters/Ducks_Mekong.asc")#
#
chickens_number = chickens_density*raster::area(chickens_density)#
ducks_number = ducks_density*raster::area(ducks_density)#
hosts = chickens_number#
hosts[] = hosts[]+ducks_number[]#
#
#Step 5: loading H5N1 occurrence records#
#
records_all = c()#
records_list = list()#
for (year in 2003:2012) {#
	records_list[[year-2002]] = read.csv(paste("H5N1_records/H5N1_",year,".csv",sep=""), header=T)[,cbind("LON","LAT")]#
	records_all = rbind(records_all, records_list[[year-2002]])#
}#
#
# Step 6: assigning a number of hosts to each admin-2 polygon#
#
hosts_counts = c()#
records_counts_list = list()#
for (i in 1:length(admin_2@polygons)) {#
	hCounts = 0#
	for (j in 1:length(admin_2@polygons[[i]]@Polygons)) {#
		coords = admin_2@polygons[[i]]@Polygons[[j]]@coords#
		p = Polygon(coords)#
		ps = Polygons(list(p),1)#
		sps = SpatialPolygons(list(ps))#
		r = mask(crop(hosts, coords), sps)#
		hCounts = hCounts + sum(r[], na.rm=T)	#
	}#
	hosts_counts = c(hosts_counts, log(hCounts+1))	#
}#
#
# Step 7: assigning an annual number of H5N1 records to each admin-2 polygon#
#
for (h in 2:length(records_list)) {#
	buffer = c()#
	for (i in 1:length(admin_2@polygons)) {#
		rCounts = 0; hCounts = 0#
		for (j in 1:length(admin_2@polygons[[i]]@Polygons)) {#
			coords = admin_2@polygons[[i]]@Polygons[[j]]@coords#
			for (k in 1:dim(records_list[[h]])[1]) {#
				if (point.in.polygon(records_list[[h]][k,1], records_list[[h]][k,2], coords[,1], coords[,2], mode.checked=FALSE) == 1) {#
					rCounts = rCounts+1#
				}#
			}#
		}#
		buffer = c(buffer, rCounts)		#
	}#
	records_counts_list[[h]] = buffer	#
}#
#
# St
admins = list()#
admins[[1]] = admin_1#
admins[[2]] = admin_2#
for (i in 1:dim(coordinates)[1]) {#
	admin = admins[[as.numeric(precisions[i])]]#
	sampling_coord = cbind(as.numeric(coordinates[i,1]),as.numeric(coordinates[i,2]))#
	sequenceID = sequenceIDs[i,1]#
	index = 0#
	for (j in 1:length(admin@polygons)) {#
		for (k in 1:length(admin@polygons[[j]]@Polygons)) {#
			if (point.in.polygon(sampling_coord[1], sampling_coord[2], admin@polygons[[j]]@Polygons[[k]]@coords[,1], admin@polygons[[j]]@Polygons[[k]]@coords[,2], mode.checked=FALSE) == 1) {#
				index = j#
			}#
		}#
	}#
	if ((index == 0) & (precisions[i]==2)) {#
		# print(paste("No initial administrative polygon admin-2 found for ",sequenceID,sep=""))#
		counter = 0#
		while (index == 0) {#
			if (runif(1,0,1) < 0.5) {#
				sampling_coord[1] = sampling_coord[1] - 0.001#
			}	else	{#
				sampling_coord[1] = sampling_coord[1] + 0.001#
			}#
			if (runif(1,0,1) < 0.5) {#
				sampling_coord[2] = sampling_coord[2] - 0.001#
			}	else	{#
				sampling_coord[2] = sampling_coord[2] + 0.001#
			}#
			for (j in 1:length(admin@polygons)) {#
				for (k in 1:length(admin@polygons[[j]]@Polygons)) {#
					if (point.in.polygon(sampling_coord[1], sampling_coord[2], admin@polygons[[j]]@Polygons[[k]]@coords[,1], admin@polygons[[j]]@Polygons[[k]]@coords[,2], mode.checked=FALSE) == 1) {#
						index = j#
					}#
				}#
			}#
		}#
	}#
	maxArea = 0; polIndex = 0#
	for (j in 1:length(admin@polygons[[index]]@Polygons)) {#
		if (maxArea < admin@polygons[[index]]@Polygons[[j]]@area) {#
			maxArea = admin@polygons[[index]]@Polygons[[j]]@area#
			polIndex = j#
		}#
	}#
	pol1 = admin@polygons[[index]]@Polygons[[polIndex]]#
	p = Polygon(pol1@coords); ps = Polygons(list(p),1); sps = SpatialPolygons(list(ps))#
	pol1 = sps; proj4string(pol1) = CRS("+init=epsg:4326")#
	coords = admin@polygons[[index]]@Polygons[[polIndex]]@coords#
	if (precisions[i] == 2) {#
		sink(file=paste("H5N1_polygons/",sequenceID,".kml",sep=""))#
		cat("<?xml version=\"1.0\" encoding=\"UTF-8\"?>"); cat("\n")#
		cat("<kml xmlns=\"http://earth.google.com/kml/2.2\">"); cat("\n")#
		cat(paste("\t<polygon id=\"",paste(sequenceID,sep="_"),"\" samplingProbability=\"",1,"\">",sep="")); cat("\n")#
		cat("\t\t<coordinates>"); cat("\n")#
		for (j in 1:dim(coords)[1]) {#
			cat(paste("\t\t\t",coords[j,2],",",coords[j,1],",0",sep="")); cat("\n")#
		}#
		cat("\t\t</coordinates>"); cat("\n")#
		cat("\t</polygon>"); cat("\n")#
		cat("</kml>"); cat("\n")#
		sink(NULL)#
	}#
	if (precisions[i] == 1) {#
		indices = which(admin2_admin1ID == index)#
		year_index = years[i,1]-2002#
		records_selected = records_counts_list[[year_index]]#
		oRecords = records_selected[indices]#
		# oRecords = records_counts[indices]#
		hRecords = hosts_counts[indices]#
		records = c()#
		if (sum(oRecords) > 0) {#
			records = oRecords#
		}	else	{#
			records = hRecords#
print(i)#
		}#
		pols2_not_included = c()#
		sink(file=paste("H5N1_polygons/",sequenceID,".kml",sep=""))#
		cat("<?xml version=\"1.0\" encoding=\"UTF-8\"?>"); cat("\n")#
		cat("<kml xmlns=\"http://earth.google.com/kml/2.2\">"); cat("\n")#
		firstPlot = TRUE#
		for (j in 1:length(indices)) {#
			fValue = records[j]/sum(records)						#
			if (fValue > 0) {#
				maxArea = 0; polIndex2 = 0#
				for (k in 1:length(admin_2@polygons[[indices[j]]]@Polygons)) {#
					if (maxArea < admin_2@polygons[[indices[j]]]@Polygons[[k]]@area) {#
						maxArea = admin_2@polygons[[indices[j]]]@Polygons[[k]]@area#
						polIndex2 = k#
					}#
				}#
				coords = admin_2@polygons[[indices[j]]]@Polygons[[polIndex2]]@coords#
				cat(paste("\t<polygon id=\"",paste(sequenceID,j,sep="_"),"\" samplingProbability=\"",fValue,"\">",sep=""))#
				cat("\n")#
				cat("\t\t<coordinates>"); cat("\n")#
				for (l in 1:dim(coords)[1]) {#
					cat(paste("\t\t\t",coords[l,2],",",coords[l,1],",0",sep="")); cat("\n")#
				}#
				cat("\t\t</coordinates>"); cat("\n")#
				cat("\t</polygon>"); cat("\n")#
				pol2 = admin_2@polygons[[indices[j]]]@Polygons[[polIndex2]]#
				p = Polygon(pol2@coords); ps = Polygons(list(p),1); sps = SpatialPolygons(list(ps)); #
				pol2 = sps; proj4string(pol2) = CRS("+init=epsg:4326")#
				if (gIntersects(pol1, pol2) == TRUE) {#
					pol3 = gIntersection(pol1, pol2)#
					if (class(pol3) == "SpatialPolygons") {#
						area2 = pol2@polygons[[1]]@area#
						area3 = pol3@polygons[[1]]@area#
						if (area3 < (0.5*area2)) {#
							pols2_not_included = c(pols2_not_included, j)#
						}#
					}#
				}#
			}#
		}#
		cat("</kml>"); cat("\n")#
		sink(NULL)#
	}#
}
records_all
head(records_all)
records_counts = c()#
for (i in 1:length(admin_2@polygons)) {#
	rCounts = 0#
	for (j in 1:length(admin_2@polygons[[i]]@Polygons)) {#
		coords = admin_2@polygons[[i]]@Polygons[[j]]@coords#
		for (k in 1:dim(records_all)[1]) {#
			if (point.in.polygon(records_all[k,1], records_all[k,2], coords[,1], coords[,2], mode.checked=FALSE) == 1) {#
				rCounts = rCounts+1#
			}#
		}#
	}#
	records_counts = c(records_counts, rCounts)		#
}
records_counts_list=list()
admins = list()#
admins[[1]] = admin_1#
admins[[2]] = admin_2#
for (i in 1:dim(coordinates)[1]) {#
	admin = admins[[as.numeric(precisions[i])]]#
	sampling_coord = cbind(as.numeric(coordinates[i,1]),as.numeric(coordinates[i,2]))#
	sequenceID = sequenceIDs[i,1]#
	index = 0#
	for (j in 1:length(admin@polygons)) {#
		for (k in 1:length(admin@polygons[[j]]@Polygons)) {#
			if (point.in.polygon(sampling_coord[1], sampling_coord[2], admin@polygons[[j]]@Polygons[[k]]@coords[,1], admin@polygons[[j]]@Polygons[[k]]@coords[,2], mode.checked=FALSE) == 1) {#
				index = j#
			}#
		}#
	}#
	if ((index == 0) & (precisions[i]==2)) {#
		# print(paste("No initial administrative polygon admin-2 found for ",sequenceID,sep=""))#
		counter = 0#
		while (index == 0) {#
			if (runif(1,0,1) < 0.5) {#
				sampling_coord[1] = sampling_coord[1] - 0.001#
			}	else	{#
				sampling_coord[1] = sampling_coord[1] + 0.001#
			}#
			if (runif(1,0,1) < 0.5) {#
				sampling_coord[2] = sampling_coord[2] - 0.001#
			}	else	{#
				sampling_coord[2] = sampling_coord[2] + 0.001#
			}#
			for (j in 1:length(admin@polygons)) {#
				for (k in 1:length(admin@polygons[[j]]@Polygons)) {#
					if (point.in.polygon(sampling_coord[1], sampling_coord[2], admin@polygons[[j]]@Polygons[[k]]@coords[,1], admin@polygons[[j]]@Polygons[[k]]@coords[,2], mode.checked=FALSE) == 1) {#
						index = j#
					}#
				}#
			}#
		}#
	}#
	maxArea = 0; polIndex = 0#
	for (j in 1:length(admin@polygons[[index]]@Polygons)) {#
		if (maxArea < admin@polygons[[index]]@Polygons[[j]]@area) {#
			maxArea = admin@polygons[[index]]@Polygons[[j]]@area#
			polIndex = j#
		}#
	}#
	pol1 = admin@polygons[[index]]@Polygons[[polIndex]]#
	p = Polygon(pol1@coords); ps = Polygons(list(p),1); sps = SpatialPolygons(list(ps))#
	pol1 = sps; proj4string(pol1) = CRS("+init=epsg:4326")#
	coords = admin@polygons[[index]]@Polygons[[polIndex]]@coords#
	if (precisions[i] == 2) {#
		sink(file=paste("H5N1_polygons/",sequenceID,".kml",sep=""))#
		cat("<?xml version=\"1.0\" encoding=\"UTF-8\"?>"); cat("\n")#
		cat("<kml xmlns=\"http://earth.google.com/kml/2.2\">"); cat("\n")#
		cat(paste("\t<polygon id=\"",paste(sequenceID,sep="_"),"\" samplingProbability=\"",1,"\">",sep="")); cat("\n")#
		cat("\t\t<coordinates>"); cat("\n")#
		for (j in 1:dim(coords)[1]) {#
			cat(paste("\t\t\t",coords[j,2],",",coords[j,1],",0",sep="")); cat("\n")#
		}#
		cat("\t\t</coordinates>"); cat("\n")#
		cat("\t</polygon>"); cat("\n")#
		cat("</kml>"); cat("\n")#
		sink(NULL)#
	}#
	if (precisions[i] == 1) {#
		indices = which(admin2_admin1ID == index)#
		year_index = years[i,1]-2002#
		# records_selected = records_counts_list[[year_index]]#
		# oRecords = records_selected[indices]#
		oRecords = records_counts[indices]#
		hRecords = hosts_counts[indices]#
		records = c()#
		if (sum(oRecords) > 0) {#
			records = oRecords#
		}	else	{#
			records = hRecords#
print(i)#
		}#
		pols2_not_included = c()#
		sink(file=paste("H5N1_polygons/",sequenceID,".kml",sep=""))#
		cat("<?xml version=\"1.0\" encoding=\"UTF-8\"?>"); cat("\n")#
		cat("<kml xmlns=\"http://earth.google.com/kml/2.2\">"); cat("\n")#
		firstPlot = TRUE#
		for (j in 1:length(indices)) {#
			fValue = records[j]/sum(records)						#
			if (fValue > 0) {#
				maxArea = 0; polIndex2 = 0#
				for (k in 1:length(admin_2@polygons[[indices[j]]]@Polygons)) {#
					if (maxArea < admin_2@polygons[[indices[j]]]@Polygons[[k]]@area) {#
						maxArea = admin_2@polygons[[indices[j]]]@Polygons[[k]]@area#
						polIndex2 = k#
					}#
				}#
				coords = admin_2@polygons[[indices[j]]]@Polygons[[polIndex2]]@coords#
				cat(paste("\t<polygon id=\"",paste(sequenceID,j,sep="_"),"\" samplingProbability=\"",fValue,"\">",sep=""))#
				cat("\n")#
				cat("\t\t<coordinates>"); cat("\n")#
				for (l in 1:dim(coords)[1]) {#
					cat(paste("\t\t\t",coords[l,2],",",coords[l,1],",0",sep="")); cat("\n")#
				}#
				cat("\t\t</coordinates>"); cat("\n")#
				cat("\t</polygon>"); cat("\n")#
				pol2 = admin_2@polygons[[indices[j]]]@Polygons[[polIndex2]]#
				p = Polygon(pol2@coords); ps = Polygons(list(p),1); sps = SpatialPolygons(list(ps)); #
				pol2 = sps; proj4string(pol2) = CRS("+init=epsg:4326")#
				if (gIntersects(pol1, pol2) == TRUE) {#
					pol3 = gIntersection(pol1, pol2)#
					if (class(pol3) == "SpatialPolygons") {#
						area2 = pol2@polygons[[1]]@area#
						area3 = pol3@polygons[[1]]@area#
						if (area3 < (0.5*area2)) {#
							pols2_not_included = c(pols2_not_included, j)#
						}#
					}#
				}#
			}#
		}#
		cat("</kml>"); cat("\n")#
		sink(NULL)#
	}#
}
xml = scan(file="BEAST_template.xml", what="", sep="\n", quiet=T)#
directory = "H5N1_polygons"#
sink(file="H5N1_clade1.xml")#
for (i in 1:length(xml)) {#
	cat(xml[i]); cat("\n")#
	if (xml[i]=="\t</continuousDiffusionStatistic>") {#
		cat("\n")#
		for (j in 1:length(sequenceIDs)) {#
			cat(paste("\t<leafTraitParameter id=\"",sequenceIDs[j],".trait\" taxon=\"",names[j],"\">",sep="")); cat("\n")#
			cat(paste("\t\t<treeModel idref=\"treeModel\"/>",sep="")); cat("\n")#
			cat(paste("\t\t<parameter idref=\"leaf.location\"/>",sep="")); cat("\n")#
			cat(paste("\t</leafTraitParameter>",sep="")); cat("\n")#
		}#
		cat("\n")#
		for (j in 1:length(sequenceIDs)) {#
			cat(paste("\t<flatGeoSpatialPrior id=\"",sequenceIDs[j],"_polygons\" taxon=\"",names[j],"\" kmlFileName=\"",directory,"/",sequenceIDs[j],".kml\" inside=\"true\" union=\"true\" cache=\"true\">",sep="")); cat("\n")#
			cat(paste("\t\t<data>",sep="")); cat("\n")#
			cat(paste("\t\t\t<parameter idref=\"",sequenceIDs[j],".trait\"/>",sep="")); cat("\n")#
			cat(paste("\t\t</data>",sep="")); cat("\n")#
			cat(paste("\t</flatGeoSpatialPrior>",sep="")); cat("\n")#
		}#
		cat("\n")		#
	}#
	if (xml[i]=="\t\t</precisionGibbsOperator>") {#
		cat("\n")#
		for (j in 1:length(sequenceIDs)) {#
			cat(paste("\t\t<uniformGeoSpatialOperator weight=\"0.01\">",sep="")); cat("\n")#
			cat(paste("\t\t\t<parameter idref=\"",sequenceIDs[j],".trait\"/>",sep="")); cat("\n")#
			cat(paste("\t\t\t<flatGeoSpatialPrior idref=\"",sequenceIDs[j],"_polygons\"/>",sep="")); cat("\n")#
			cat(paste("\t\t</uniformGeoSpatialOperator>",sep="")); cat("\n")#
		}#
		cat("\n")#
	}#
	if (xml[i]=="\t\t\t\t<multivariateWishartPrior idref=\"location.precisionPrior\"/>") {#
		cat("\n")#
		cat("\t\t\t\t<geoDistributionCollection id=\"allGeoDistributions\">"); cat("\n")#
		for (j in 1:length(sequenceIDs)) {#
			cat(paste("\t\t\t\t<flatGeoSpatialPrior idref=\"",sequenceIDs[j],"_polygons\"/>",sep="")) #
			cat("\n")#
		}#
		cat("\t\t\t\t</geoDistributionCollection>"); cat("\n")#
		cat("\n")#
	}					#
	if (xml[i]=="\t\t\t<multivariateTraitLikelihood idref=\"location.traitLikelihood\"/>") {#
		if (xml[i-3]=="\t\t\t<strictClockBranchRates idref=\"branchRates\"/>") {#
			cat("\n")#
			for (j in 1:length(sequenceIDs)) {#
				cat(paste("\t\t\t<leafTraitParameter idref=\"",sequenceIDs[j],".trait\"/>",sep="")); cat("\n")#
			}#
			cat("\n")#
		}#
	}	#
}#
sink(NULL)
